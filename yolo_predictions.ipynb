{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a8cf797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c758bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:/OneDrive/OneDrive - Tata Insights and Quants/vision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c01bc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'car',\n",
       " 'chair',\n",
       " 'bottle',\n",
       " 'pottedplant',\n",
       " 'bird',\n",
       " 'dog',\n",
       " 'sofa',\n",
       " 'bicycle',\n",
       " 'horse',\n",
       " 'boat',\n",
       " 'motorbike',\n",
       " 'cat',\n",
       " 'tvmonitor',\n",
       " 'cow',\n",
       " 'sheep',\n",
       " 'aeroplane',\n",
       " 'train',\n",
       " 'diningtable',\n",
       " 'bus']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load YAML\n",
    "with open('data.yaml', mode='r') as f:\n",
    "    data_yaml = yaml.load(f, Loader=SafeLoader)\n",
    "labels =data_yaml['names']\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eb7c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Yolo model using opencv\n",
    "yolo = cv2.dnn.readNetFromONNX('2_predictions/Model/weights/best.onnx') \n",
    "yolo.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "yolo.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0308d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the image\n",
    "img = cv2.imread('2_predictions/street_image.jpg')\n",
    "image = img.copy()\n",
    "cv2.imshow('image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aad8e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('2_predictions/street_image.jpg')\n",
    "image = img.copy()\n",
    "row, col, d = image.shape #store the shape of the image (number of rows, columns, and channels) in the variables row, col, and d.\n",
    "\n",
    "# get the YOLO prediction from the the image\n",
    "# step-1 convert image into square image (array)\n",
    "max_rc = max(row,col)\n",
    "input_image = np.zeros((max_rc,max_rc,3),dtype=np.uint8) #To display a blank image with square image array\n",
    "cv2.imshow('input_image', input_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a5ced9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image[0:row,0:col] = image #To overlay street_image on the black iamge\n",
    "cv2.imshow('input_image', input_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68f3bfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25200, 25)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step-2: get yolo predictions from square array image\n",
    "\n",
    "\"\"\"\n",
    "This line preprocesses the input image by creating a \"blob\",\n",
    "which is a 4D NumPy array that is compatible with the YOLO model's input format.\n",
    "The blobFromImage() function resizes the input image to (INPUT_WH_YOLO x INPUT_WH_YOLO),\n",
    "normalizes the pixel values to be in the range [0,1],\n",
    "and optionally swaps the Red and Blue channels (because YOLO expects input images in BGR order).\n",
    "The resulting blob is a 4D NumPy array that has dimensions (1, 3, INPUT_WH_YOLO, INPUT_WH_YOLO).\n",
    "\"\"\"\n",
    "INPUT_WH_YOLO = 640\n",
    "blob = cv2.dnn.blobFromImage(input_image,1/255,(INPUT_WH_YOLO,INPUT_WH_YOLO),swapRB=True,crop=False)\n",
    "yolo.setInput(blob) \n",
    "preds = yolo.forward() # passing the blob to the neural network for detection or prediction from YOLO\n",
    "#The forward() function returns a 4D NumPy array preds that has dimensions (1, n, 1, 7) \n",
    "# where n is the number of detected objects and 7 represents the output format of YOLO model which includes\n",
    "# the center coordinates (x, y), width, height, confidence score, and class probabilities for each detected object.\n",
    "\n",
    "preds.shape # 25200 bounding boxes detected by yolo in 25 columns\n",
    "# 1st 5 columns represnts CenterX, CenterY, w, h, confidence score of BB,\n",
    "# Next 20 columns representing classification score of each class(20 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29ce1270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25200, 25), (1920, 1920))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].shape, input_image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c901807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.2053843e+00, 5.6192646e+00, 1.5319378e+01, 1.2029615e+01,\n",
       "       3.1126863e-06, 2.9626408e-01, 4.1468356e-02, 2.8888814e-02,\n",
       "       1.3442527e-02, 7.0562646e-02, 6.4744771e-02, 8.1728483e-03,\n",
       "       6.2823361e-03, 8.4436266e-03, 1.6425727e-02, 1.1815503e-02,\n",
       "       4.2724703e-03, 2.1813011e-02, 1.8395778e-02, 1.9731700e-02,\n",
       "       5.8100011e-02, 2.6430789e-02, 1.8664990e-02, 3.4893681e-03,\n",
       "       1.1641061e-02], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections = preds[0]\n",
    "detections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca882d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([291, 122, 175, 312,  93, 230, 151, 105, 189, 253, 136, 108,  69,\n",
       "       275, 289, 262, 168,  32, 172, 179, 103, 261])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non Maximum Supression(to removed duplicate detections, select BB with high confidence and prob. scores)\n",
    "# step-1: filter detection based on confidence (0.4) and probability score (0.25)\n",
    "detections = preds[0]\n",
    "boxes = []\n",
    "confidences = []\n",
    "classes = []\n",
    "\n",
    "# widht and height of the image (input_image)\n",
    "image_w, image_h = input_image.shape[:2]\n",
    "x_factor = image_w/INPUT_WH_YOLO #factor by which BB info is multiplied\n",
    "y_factor = image_h/INPUT_WH_YOLO\n",
    "\n",
    "for i in range(len(detections)):\n",
    "    row = detections[i]\n",
    "    confidence = row[4] # confidence of detection an object\n",
    "    if confidence > 0.4:\n",
    "        class_score = row[5:].max() # maximum probability from 20 objects\n",
    "        class_id = row[5:].argmax() # get the index position at which max probabilty occur\n",
    "        \n",
    "        if class_score > 0.25:\n",
    "            cx, cy, w, h = row[0:4]\n",
    "            # construct bounding from four values\n",
    "            # left, top, width and height\n",
    "            left = int((cx - 0.5*w)*x_factor)\n",
    "            top = int((cy - 0.5*h)*y_factor)\n",
    "            width = int(w*x_factor)\n",
    "            height = int(h*y_factor)\n",
    "            \n",
    "            box = np.array([left,top,width,height])\n",
    "            \n",
    "            # append values into the list\n",
    "            confidences.append(confidence)\n",
    "            boxes.append(box)\n",
    "            classes.append(class_id)\n",
    "            \n",
    "# clean\n",
    "boxes_np = np.array(boxes).tolist()\n",
    "confidences_np = np.array(confidences).tolist()\n",
    "\n",
    "# NMS\n",
    "index = cv2.dnn.NMSBoxes(boxes_np,confidences_np,0.25,0.45).flatten()\n",
    "index #From this image we found that 24 objects rows that are having good confidence score and good probablitity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3e7dbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the Bounding Box\n",
    "for ind in index:\n",
    "    #extract bounding box\n",
    "    x,y,w,h = boxes_np[ind]\n",
    "    bb_conf = int(confidences_np[ind]*100)\n",
    "    classes_id = classes[ind]\n",
    "    class_name = labels[classes_id]\n",
    "\n",
    "    text = f'{class_name}: {bb_conf}%'\n",
    "    #print(text)\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "    cv2.rectangle(image,(x,y-30),(x+w,y),(255,255,255),-1)\n",
    "    cv2.putText(image,text, (x,y-10), cv2.FONT_HERSHEY_PLAIN,0.7,(0,0,0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "887ba437",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('original',img)\n",
    "cv2.imshow('yolo_prediction',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd30a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516bb30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
